{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85eaf109",
   "metadata": {},
   "source": [
    "# VGG-19 Based Grayscale Image Colorization\n",
    "\n",
    "This notebook colorizes a grayscale image using a VGG-19 based model\n",
    "and applies CLAHE as a **post-processing step** for contrast enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5acb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fde32",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 224\n",
    "INPUT_IMAGE = \"sampleimage.jpg\"\n",
    "WEIGHTS_PATH = \"colorization_vgg19_weights.h5\"\n",
    "OUTPUT_IMAGE = \"final_colorized_clahe.jpg\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa10e7",
   "metadata": {},
   "source": [
    "## Load Grayscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.imread(INPUT_IMAGE, cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    raise FileNotFoundError(\"Input image not found!\")\n",
    "\n",
    "gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "L = gray.astype(\"float32\") / 255.0\n",
    "L = L * 100.0\n",
    "L_input = L.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08823676",
   "metadata": {},
   "source": [
    "## Build VGG-19 Colorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg = VGG19(weights=\"imagenet\", include_top=False,\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "vgg.trainable = False\n",
    "\n",
    "vgg_features = Model(\n",
    "    inputs=vgg.input,\n",
    "    outputs=vgg.get_layer(\"block4_conv4\").output\n",
    ")\n",
    "\n",
    "input_L = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "x = Conv2D(3, (1,1), padding=\"same\")(input_L)\n",
    "features = vgg_features(x)\n",
    "\n",
    "x = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(features)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "\n",
    "output_ab = Conv2D(2, (3,3), activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "model = Model(input_L, output_ab)\n",
    "model.compile(optimizer=Adam(1e-4), loss=\"mse\")\n",
    "\n",
    "model.load_weights(WEIGHTS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddd180",
   "metadata": {},
   "source": [
    "## Colorize Image Using VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_ab = model.predict(L_input)[0]\n",
    "pred_ab = pred_ab * 128.0\n",
    "\n",
    "lab_output = np.zeros((IMG_SIZE, IMG_SIZE, 3))\n",
    "lab_output[:,:,0] = L\n",
    "lab_output[:,:,1:] = pred_ab\n",
    "\n",
    "rgb_colorized = lab2rgb(lab_output)\n",
    "rgb_colorized_uint8 = (rgb_colorized * 255).astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afa87e",
   "metadata": {},
   "source": [
    "## Post-processing with CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lab_post = rgb2lab(rgb_colorized_uint8)\n",
    "L_post = lab_post[:,:,0].astype(\"uint8\")\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "L_enhanced = clahe.apply(L_post)\n",
    "\n",
    "lab_post[:,:,0] = L_enhanced\n",
    "final_rgb = lab2rgb(lab_post)\n",
    "final_rgb = (final_rgb * 255).astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f112797",
   "metadata": {},
   "source": [
    "## Save and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imwrite(\n",
    "    OUTPUT_IMAGE,\n",
    "    cv2.cvtColor(final_rgb, cv2.COLOR_RGB2BGR)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Input Grayscale\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"VGG-19 Colorized\")\n",
    "plt.imshow(rgb_colorized_uint8)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Colorized + CLAHE (Post)\")\n",
    "plt.imshow(final_rgb)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Colorization completed successfully.\")\n",
    "print(f\"Output saved as: {OUTPUT_IMAGE}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
